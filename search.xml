<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[和我一起走近 git]]></title>
    <url>%2F2019%2F01%2F18%2Fgit%2F</url>
    <content type="text"><![CDATA[git 设置123456789# 配置用户名和邮箱$ git config --global user.name "gethin"$ git config --global user.email "gethin.yan@gmail.com"# Unix/Mac 用户$ git config --global core.autocrlf input$ git config --global core.safecrlf true# Windows 用户$ git config --global core.autocrlf true$ git config --global core.safecrlf true 关于 CRLF 和 LFLinux/Mac OS 以 LF(\n) 结尾，而 Windows 以 CRLF(\r\n) 结尾 123456# 提交时转换为 LF，检出时转换为 CRLF$ git config --global core.autocrlf true# 提交时转换为 LF，检出时不转换$ git config --global core.autocrlf input# 提交检出均不转换$ git config --global core.autocrlf false safecrlf 选项是针对提交时的配置，当有混用的情况发生的时候 git 应该给出的一些表现 123456# 拒绝提交包含混合换行符的文件git config --global core.safecrlf true# 允许提交包含混合换行符的文件git config --global core.safecrlf false# 提交包含混合换行符的文件时给出警告git config --global core.safecrlf warn 别名添加下列内容到你的 $HOME 目录的 .gitconfig 文件中 12345678[alias] co = checkout ci = commit st = status br = branch hist = log --pretty=format:&apos;%h %ad | %s%d [%an]&apos; --graph --date=short type = cat-file -t dump = cat-file -p GitHub SSH Keys使用 SSH 协议，您可以连接和验证远程服务器和服务。 使用 SSH 密钥，您可以连接到 GitHub，而无需在每次访问时提供用户名或密码 ssh-keygen 生成秘钥ssh-keygen 命令用于为 ssh 生成、管理和转换认证秘钥，它支持 RSA 和 DSA 两种认证秘钥，秘钥文件放在 ~/.ssh 文件夹中(~是用户根目录)，运行下面命令生成秘钥，密码为空(只需要按回车) 12# -t 指定类型，-C 添加注释$ ssh-keygen -t rsa -C "gethin.yan@gmail.com" 公钥放到 GitHub生成秘钥之后进入 ~/.ssh 文件夹下，复制 id_rsa.pub 文件的所有内容 1打开 GitHub -&gt; settings -&gt; SSH and GPG keys -&gt; New SSH key -&gt; 将复制的内容添加进去 测试是否设置成功1234$ ssh git@github.comPTY allocation request failed on channel 0Hi gethinyan! You've successfully authenticated, but GitHub does not provide shell access.Connection to github.com closed. git 基础概念 workspace （工作区） stage （暂存区） repository （本地仓库） remote （远程仓库） git 基本命令因为习惯使用 git 图形化工具，所以很多时候使用 git 命令的时候需要去查，此处记录常用的基本命令方便随时查看 创建仓库1$ git init 检出仓库1$ git clone [local repository | remote] 添加文件到暂存区1$ git add [filename | . | -A | *] 查看工作目录状态1$ git stauts 比较差异1$ git diff [filename] 提交到仓库12# 这里 -am 不支持新建文件$ git commit [-m | -am] 撤销修改1234# 添加到暂存区的修改$ git reset HEAD filename# 未添加到暂存区的修改$ git checkout -- filename 删除文件1$ git rm filename 移动文件1$ git mv filename path 分支1$ git branch [-a | -r | -d | -D ] 切换分支1$ git checkout [-b] branch 合并分支12$ git merge branch$ git rebase branch 回滚12$ git reset [--soft | --mixed(default) | --hard] [HEAD~number | commit Id]$ git revert [HEAD~number | commit Id] 提交历史1$ git log --pretty=format:'%h %ad | %s%d [%an]' --graph --date=short 储藏/弹出修改12$ git stash$ git stash pop 标签1$ git tag 同步远端1$ git fetch 同步远端并合并1$ git pull remote branch [local branch] 同步到远端1$ git push remote branch 管理主机名1$ git remote [-v | add | rm | rename] 设置代理12$ git config --global https.proxy 'socks5://127.0.0.1:1086'$ git config --global http.proxy 'socks5://127.0.0.1:8086' 取消代理12$ git config --global --unset https.proxy$ git config --global --unset http.proxy git 子模块子模块初始化拉代码1$ git submodule update --init 子模块拉远程代码12# 也可以进入子模块的文件夹 git pull$ git submodule update --remote 添加子模块1$ git submodule add remote 删除子模块12$ git submodule deinit submodule$ git rm --cached submodule 修改子模块 url12# 先 vim .gitmodules 修改对应子模块的 url$ git submodule sync]]></content>
      <tags>
        <tag>git</tag>
        <tag>GitHub</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Kafka 初体验]]></title>
    <url>%2F2019%2F01%2F16%2Fkafka%2F</url>
    <content type="text"><![CDATA[Kakfa 简介Apache Kafka 是一个分布式流处理平台 流处理平台三种特性 可以让你发布和订阅流式的记录。这一方面与消息队列或者企业消息系统类似 可以储存流式的记录，并且有较好的容错性 可以在流式记录产生时就进行处理 Kafka 适用场景 构造实时流数据管道，它可以在系统或应用之间可靠地获取数据（相当于 message queue） 构建实时流式应用程序，对这些流数据进行转换或者影响（就是流处理，通过 kafka stream topic 和 topic 之间内部进行变化） Kafka 四个核心 APIProducer APIThe Producer API 允许一个应用程序发布一串流式的数据到一个或者多个 Kafka topic Consumer APIThe Consumer API 允许一个应用程序订阅一个或多个 topic ，并且对发布给他们的流式数据进行处理 Streams APIThe Streams API 允许一个应用程序作为一个流处理器，消费一个或者多个 topic 产生的输入流，然后生产一个输出流到一个或多个 topic 中去，在输入输出流中进行有效的转换 Connector APIThe Connector API 允许构建并运行可重用的生产者或者消费者，将 Kafka topics 连接到已存在的应用程序或者数据系统。比如，连接到一个关系型数据库，捕捉表（table）的所有变更内容 Kafka 依赖环境 Gradle Java 安装依赖环境安装 Java下载源码并解压12345678910# 进入 root 用户根目录$ cd /root# 创建 source 文件夹用于存放源码压缩包$ mkdir source &amp;&amp; cd source# 下载 Jdk 源码$ wget https://download.oracle.com/otn-pub/java/jdk/8u191-b12/2787e4a523244c269598db4e85c51e0c/jdk-8u191-linux-x64.tar.gz?AuthParam=1547191561_cd6fc31e988d398c5a0c796e2a033d89 -O jdk-8u191-linux-x64.tar.gz# 解压$ tar -zxvf jdk-8u191-linux-x64.tar.gz# 移动到 root 用户根目录$ mv jdk-11.0.1 /root/jdk 配置 Path可以针对全局配置文件 /etc/profile 添加 jdk 的 bin 和 jre 文件夹的目录，同样也可以针对 root 用户配置用户的配置文件 /etc/profile 12# 在 export 前面添加下面代码PATH=$PATH:/root/jdk/bin:/root/jdk/jre ~/.bash_profile 12# 在 export 前面添加下面代码，也可以就在 PATH= 后面添加 :/root/jdk/bin:/root/jdk/jrePATH=$PATH:/root/jdk/bin:/root/jdk/jre 在配置好了之后别忘了使用 source &lt;profile path&gt; 命令让新配置文件生效 安装 Gradle下载源码并解压12345678910# 进入 source 文件夹$ cd /root/source# 下载 Gradle 源码$ wget https://downloads.gradle.org/distributions/gradle-5.1.1-bin.zip# 安装 unzip 命令（已安装请忽略）$ yum install unzip# 解压$ unzip gradle-5.1.1-bin.zip# 移动到 root 用户根目录$ mv gradle-5.1.1 /root/gradle gradle -v 1234567891011121314&gt; ------------------------------------------------------------&gt; Gradle 5.1.1&gt; ------------------------------------------------------------&gt;&gt; Build time: 2019-01-10 23:05:02 UTC&gt; Revision: 3c9abb645fb83932c44e8610642393ad62116807&gt;&gt; Kotlin DSL: 1.1.1&gt; Kotlin: 1.3.11&gt; Groovy: 2.5.4&gt; Ant: Apache Ant(TM) version 1.9.13 compiled on July 10 2018&gt; JVM: 1.8.0_191 (Oracle Corporation 25.191-b12)&gt; OS: Linux 3.10.0-957.1.3.el7.x86_64 amd64&gt; 配置 Path同 Java 的配置方式，只需把 Gradle 的 bin 目录 /root/gradle/bin 加入 PATH即可 1PATH=$PATH:/root/gradle/bin 安装 Kafka下载源码并解压123456# 下载 Kafka 源码$ wget http://archive.apache.org/dist/kafka/2.1.0/kafka_2.11-2.1.0.tgz# 解压源码$ tar -zxvf kafka_2.11-2.1.0.tgz# 移动到指定目录$ mv kafka_2.11-2.1.0 /path/to/kafka 启动服务器 下面的命令都是在 Kafka 的根目录运行的，请先进入 Kafka 的根目录 启动 ZooKeeper 服务器1$ bin/zookeeper-server-start.sh config/zookeeper.properties &amp; 启动 Kafka 服务器1$ bin/kafka-server-start.sh config/server.properties &amp; 创建一个 topic1$ bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic test 查看 topic123$ bin/kafka-topics.sh --list --zookeeper localhost:2181__consumer_offsetstest 发送消息运行 producer（生产者），然后在控制台输入一些消息以发送到服务器 123$ bin/kafka-console-producer.sh --broker-list localhost:9092 --topic test&gt;This is a message&gt;This is another message 接收消息Kafka 还有一个命令行 consumer（消费者），将消息转储到标准输出 123$ bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test --from-beginningThis is a messageThis is another message php 处理 Kafka 消息编译安装 librdkafka123456789# 下载 librdkafka 源码$ wget https://github.com/edenhill/librdkafka/archive/v0.11.6.tar.gz# 解压源码$ tar -zxvf v0.11.6.tar.gz# 进入 librdkafka 文件夹$ cd librdkafka-0.11.6# 编译安装 librdkafka$ ./configure$ make &amp;&amp; make install 编译安装 php-rdkafka 扩展12345678910111213$ su work$ cd /home/work/source# 下载 php-rdkafka 源码$ wget https://github.com/arnaud-lb/php-rdkafka/archive/3.0.5.tar.gz# 解压源码$ tar -zxvf 3.0.5.tar.gz# 进入 php-rdkafka 文件夹$ cd php-rdkafka-3.0.5# 运行 phpize 命令，写全 phpize 的路径$ /home/work/orp/php/bin/phpize# 编译安装 php-rdkafka$ ./configure --with-php-config=/home/work/orp/php/bin/php-config$ make all -j 5 &amp;&amp; make install 配置 php.ini编辑 php.ini 文件12# 把安装好的扩展加加入 php.iniextension=rdkafka.so 重启 php-fpm12345678# 查看 php-fpm 进程$ ps -ef | grep phpwork 6817 0 0 08:19 ? 00:00:00 php-fpm: master process (/home/work/orp/php/etc/php-fpm.conf)work 6818 6817 0 08:19 ? 00:00:00 php-fpm: pool wwwwork 6819 6817 0 08:19 ? 00:00:00 php-fpm: pool wwwwork 6840 2732 0 08:24 pts/1 00:00:00 grep php# 重启 php-fpm$ kill -USR2 38 现在打开 phpinfo 页面搜索 rdkafka 扩展可以看到我们已经成功安装了 rdkafka 扩展，下面我们将在实战中使用到 Kafka 生产者 Producerphp 代码123456789&lt;?php$rk = new RdKafka\Producer();$rk-&gt;setLogLevel(LOG_DEBUG);// 配置 Kafka 的 ip 地址，我这里是容器调用宿主机里的 Kafka$rk-&gt;addBrokers('172.17.0.1');$topic = $rk-&gt;newTopic('test');$topic-&gt;produce(RD_KAFKA_PARTITION_UA, 0, 'Message payload'); 运行生产者代码1$ /home/work/orp/php/bin/php /home/work/orp/webroot/producer.php 运行 Kafka 消费者查看1234$ cd /root/kafka$ bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test --from-beginningMessage payloadMessage payload 消费者 ConsumerLow-level consumerphp 代码1234567891011121314151617181920212223&lt;?php$rk = new RdKafka\Consumer();$rk-&gt;setLogLevel(LOG_DEBUG);$rk-&gt;addBrokers('172.17.0.1');$topic = $rk-&gt;newTopic('test');// The first argument is the partition to consume from.// The second argument is the offset at which to start consumption. Valid values// are: RD_KAFKA_OFFSET_BEGINNING, RD_KAFKA_OFFSET_END, RD_KAFKA_OFFSET_STORED.$topic-&gt;consumeStart(0, RD_KAFKA_OFFSET_BEGINNING);while (true) &#123; // The first argument is the partition (again). // The second argument is the timeout. $msg = $topic-&gt;consume(0, 1000); if ($msg-&gt;err) &#123; echo $msg-&gt;errstr(), "\n"; break; &#125; else &#123; echo $msg-&gt;payload, "\n"; &#125;&#125; 运行低级消费者 php 代码 可以看到我们已经成功的接收到了生产者生产的消息 1234$ /home/work/orp/php/bin/php consumer.phpMessage payloadMessage payloadBroker: No more messages High-level consumerphp 代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566&lt;?php$conf = new RdKafka\Conf();// Set a rebalance callback to log partition assignments (optional)$conf-&gt;setRebalanceCb(function (RdKafka\KafkaConsumer $kafka, $err, array $partitions = null) &#123; switch ($err) &#123; case RD_KAFKA_RESP_ERR__ASSIGN_PARTITIONS: echo 'Assign: '; var_dump($partitions); $kafka-&gt;assign($partitions); break; case RD_KAFKA_RESP_ERR__REVOKE_PARTITIONS: echo 'Revoke: '; var_dump($partitions); $kafka-&gt;assign(null); break; default: throw new \Exception($err); &#125;&#125;);// Configure the group.id. All consumer with the same group.id will consume// different partitions.$conf-&gt;set('group.id', 'myConsumerGroup');// Initial list of Kafka brokers$conf-&gt;set('metadata.broker.list', '172.17.0.1');$topicConf = new RdKafka\TopicConf();// Set where to start consuming messages when there is no initial offset in// offset store or the desired offset is out of range.// 'smallest': start from the beginning$topicConf-&gt;set('auto.offset.reset', 'smallest');// Set the configuration to use for subscribed/assigned topics$conf-&gt;setDefaultTopicConf($topicConf);$consumer = new RdKafka\KafkaConsumer($conf);// Subscribe to topic 'test'$consumer-&gt;subscribe(['test']);echo "Waiting for partition assignment... (make take some time when\n";echo "quickly re-joining the group after leaving it.)\n";while (true) &#123; $message = $consumer-&gt;consume(120 * 1000); switch ($message-&gt;err) &#123; case RD_KAFKA_RESP_ERR_NO_ERROR: var_dump($message); break; case RD_KAFKA_RESP_ERR__PARTITION_EOF: echo "No more messages; will wait for more\n"; break; case RD_KAFKA_RESP_ERR__TIMED_OUT: echo "Timed out\n"; break; default: throw new \Exception($message-&gt;errstr(), $message-&gt;err); break; &#125;&#125; 运行高级消费者 php 代码12345678910111213141516171819202122232425262728293031323334$ /home/work/orp/php/bin/php highConsumer.phpobject(RdKafka\Message)#6 (7) &#123; ["err"]=&gt; int(0) ["topic_name"]=&gt; string(4) "test" ["partition"]=&gt; int(0) ["payload"]=&gt; string(15) "Message payload" ["len"]=&gt; int(15) ["key"]=&gt; NULL ["offset"]=&gt; int(23)&#125;object(RdKafka\Message)#5 (7) &#123; ["err"]=&gt; int(0) ["topic_name"]=&gt; string(4) "test" ["partition"]=&gt; int(0) ["payload"]=&gt; string(15) "Message payload" ["len"]=&gt; int(15) ["key"]=&gt; NULL ["offset"]=&gt; int(24)&#125;No more messages; will wait for more 遇到的问题容器内访问不到容器外的端口问题描述在运行消费者、生产者的时候，报错最多的就是 &#39;hostname:9092&#39;: Name or service not known，最开始使用的是 172.17.0.1 宿主机的 ip 去调用的，出现的上述问题，后又用外网 ip 去调用，因为安全组导致端口未暴露，所以在阿里云管理控制台的安全组加了 9092，加了安全组在线工具检测 9092 端口是打开状态，但是在运行生产者代码的时候还是会报错 &#39;hostname:9092&#39;: Name or service not known，于是我自闭了 解决方案其实通过报错 &#39;hostname:9092&#39;: Name or service not known 我们可以得知系统不知道这个 hostname，于是我尝试性的在 /etc/hosts 文件里面加了一行 172.17.0.1 hostname，然后重启网络，莫名其妙的就成功了，取消自闭模式 关闭防火墙导致访问不到外网问题描述因为不知道是不是因为防火墙的问题，所以就偷偷的把防火墙给关了，结果后面发现容器里面连不上外网，发现这个问题是看到同事在本地使用 127.0.0.1 调用成功了，所以打算在容器里装上 Kafka 然后用 127.0.0.1 调用，结果连不上网无法 wget 下载源码包 解决方案重启 docker，然后 dokcer start container 启动容器即可，经过上机测试，需要注意的是 docker 容器能不能访问到外网跟 docker 启动的那一刻宿主机的防火墙状态有关系，宿主机防火墙是关闭的那么开启之后需要重启 docker 容器才能访问外网，反之同理]]></content>
      <tags>
        <tag>CentOS</tag>
        <tag>Kafka</tag>
        <tag>php</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用 Hexo + Next 搭建博客]]></title>
    <url>%2F2019%2F01%2F04%2Fhexo-next%2F</url>
    <content type="text"><![CDATA[Hexo什么是 Hexo？ Hexo 是一个快速、简洁且高效的博客框架 Hexo 使用 Markdown（或其他渲染引擎）解析文章，在几秒内，即可利用靓丽的主题生成静态网页 安装 Hexo安装前请确保已经安装以下环境 Node.js git 安装 Hexo 命令1$ npm install -g hexo-cli 安装完成后执行以下命令即可12345678# 进入你期望存放的目录创建 blog 文件夹$ cd ~ &amp;&amp; mkdir blog# 使用 hexo 初始化 blog$ hexo init blog$ cd blog$ npm install# 启动服务器。默认情况下，访问网址为： http://localhost:4000/$ hexo s 至此，我们已经完成了万里长征的第一步，但是 Hexo 默认的主题不太好看，推荐使用简洁好看的 Next 主题，下面介绍如何结合 Next 使用 Next 主题安装 Next 主题在终端窗口下，定位到 Hexo 站点目录下12$ cd ~/blog$ git clone https://github.com/theme-next/hexo-theme-next themes/next 启用 Next 主题，打开 ~/blog/_config.yml 修改 theme1theme: next 重新启动服务器1$ hexo s 好了，现在打开 http://0.0.0.0:4000/ 看看我们的博客发生了什么变化吧 上传到 github 通过 username.github.io 访问部署博客代码安装 hexo-deployer-git1$ npm install hexo-deployer-git --save 打开 ~/blog/_config.yml 配置 deploy1234deploy: type: git repo: https://github.com/gethinyan/gethinyan.github.io.git # 替换为你的仓库路径 branch: master 部署代码，部署前需要创建仓库 username.github.io1hexo d -g 现在打开 http://0.0.0.0:4000/ https://username.github.io/ 看看是否成功了呢 使用 travis 完成自动构建、部署Activate repository在做下面的操作前请先打开 https://www.travis-ci.org active 你的 Hexo 项目 设置 Environment Variables 打开 settings 页面 添加 Environment Variables 添加变量 GITHUB_TOKEN，值在 https://github.com/settings/tokens 生成即可 在 Hexo 项目根目录添加文件 .travis.yml12345678910111213141516171819202122232425language: node_jsnode_js: stablecache: apt: true directories: - node_modulesinstall:- npm installscript:- hexo clean- hexo gafter_script:- cd ./public- git init- git config user.name "gethin.yan"- git config user.email "gethin.yan@gmail.com"- git add .- git commit -m "update notes"- git push --force --quiet "https://$&#123;GITHUB_TOKEN&#125;@$&#123;GH_REF&#125;" master:masterbranches: only: - masterenv: global: - GH_REF: github.com/gethinyan/gethinyan.github.io.git 现在试试把 Hexo 的代码 push 到 github 上，打开 https://www.travis-ci.org 对应项目的 Build History，查看构建的过程，成功后你会发现仓库 username.github.io 的文件刚被更新 github Webhooks 实现服务器自动拉代码 以下的文档适用于有自己的云服务器的盆友，想要实现自动部署博客代码到自己的服务器上 添加 webhook打开仓库 username.github.io 的 settings &gt; Webhooks 添加一个 webhook，值为 http://yourip:10002/，secret 自己设置一个，在下面的脚本需要用到 开启服务监听 webhook 配置的 10002 端口现在需要开启一个服务监听 10002 端口并且 secret 是 Webhook 配置的 secret，然后执行一个脚本 deploy.sh，在脚本里面去拉最新的代码到我们的 webroot 1234567891011121314151617181920212223242526272829303132# webhook.jsconst http = require('http')const webhookHandler = require('github-webhook-handler')const handler = webhookHandler(&#123; path: '/', secret: '123456' &#125;)function cmd (cmd, args, callback) &#123; const spawn = require('child_process').spawn const child = spawn(cmd, args) let res = '' child.stdout.on('data', buffer =&gt; &#123; res += buffer.toString() &#125;) child.stdout.on('end', () =&gt; &#123; callback(res) &#125;)&#125;http.createServer((req, res) =&gt; &#123; handler(req, res, err =&gt; &#123; res.statusCode = 404 res.end('no such loacion') &#125;)&#125;).listen(10002)handler.on('error', err =&gt; &#123; console.error('Error: ', err.message)&#125;)handler.on('push', event =&gt; &#123; const &#123; repository, ref &#125; = event.payload console.log(`Reveived a push event for $&#123;repository.name&#125; to $&#123;ref&#125;`) cmd('sh', ['./deploy.sh', repository.name], text =&gt; &#123; console.log(text) &#125;)&#125;) 启动服务12345# 进入到 webhook.js 的目录运行下面命令$ npm install github-webhook-handler$ npm install pm2 -g$ pm2 start webhook.js$ pm2 startup 不妨试试添加一个 test.md 并发布 push 到 github，首先在 travis 构建部署成功，然后触发 webhook，最后新的代码部署到我们的服务器，打开你的博客地址就能看到 test 了 travis 命令实现免登录 ssh 部署代码安装 travis安装 ruby1$ yum install rubygems 更新 gem，设置镜像源12$ gem update --system$ gem sources --add https://gems.ruby-china.org/ 使用 gem 安装 travis1$ gem install travis travis 配置登录 travis1$ travis login 使用 travis 加密公钥文件1$ travis encrypt-file ~/.ssh/id_rsa --add 查看 .travis.yml 的变化123456789before_deploy:- openssl aes-256-cbc -K $encrypted_99fb0ffd7f47_key -iv $encrypted_99fb0ffd7f47_iv -in id_rsa.enc -out /tmp/id_rsa -d- eval "$(ssh-agent -s)"- chmod 600 /tmp/id_rsa- ssh-add /tmp/id_rsaafter_success: - ssh -o StrictHostKeyChecking=no root@youtip "bash ./deploy.sh"]]></content>
      <tags>
        <tag>Hexo</tag>
        <tag>GitHub Pages</tag>
        <tag>Next</tag>
        <tag>travis</tag>
        <tag>deploy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[rsync & sersync 实现文件同步]]></title>
    <url>%2F2019%2F01%2F02%2Frsync%2F</url>
    <content type="text"><![CDATA[背景由于一台主服务器压力比较大，需要启用备用机开启负载均衡减轻主服务器的压力，同步主服务器的代码、静态资源到从服务器让从服务器跑起来 从服务器安装 rsync1234# 查看是否安装rsync$ rpm -qa | grep rsync# 安装rsync$ yum install rsync -y 配置文件 /etc/rsyncd.conf 可以配置 hosts allow 只接受允许的 ip 的同步请求 12345678910111213141516171819202122232425262728uid = rootgid = root# 最大连接数max connections = 4# 默认为true，修改为no，增加对目录文件软连接的备份use chroot = no# 允许进行数据同步的客户端IP地址，可以设置多个，用英文状态下逗号隔开# hosts allow = 47.52.175.26# 定义日志存放位置log file = /var/log/rsyncd.log# 忽略无关错误ignore errors = yes# 设置rsync服务端文件为读写权限read only = no# 认证的用户名与系统帐户无关在认证文件做配置，如果没有这行则表明是匿名auth users = rsync# 密码认证文件，格式(虚拟用户名:密码）secrets file = /etc/rsync.pass# 这里是认证的模块名，在client端需要指定，可以设置多个模块和路径[webroot]# 自定义注释comment = webroot# 文件存放的路径path = /home/work/orp/webroot[static]comment = staticpath = /home/work/orp/static 密码文件123$ echo test:test &gt; /etc/rsync.pass# 需要注意的是必须把密码文件的权限设为600，否则会报错$ chmod 600 /etc/rsync.pass 运行 rsync12# 因为rsync默认监听的是873端口，需要用root权限运行$ rsync --daemon 主服务器安装 rsync1234# 查看是否安装rsync$ rpm -qa | grep rsync# 安装rsync$ yum install rsync -y 解压 sersync1234# 为了方便，已经下好了sersync的安装包，只需解压并移到自己想要的地方即可$ cd ~ &amp;&amp; tar -zxvf sersync2.5.4_64bit_binary_stable_final.tar.gz$ mv GNU-Linux-x86 sersync$ rm sersync2.5.4_64bit_binary_stable_final.tar.gz 配置 sersync123456# 创建不同的目录区分文件类型，然后创建一个密码文件内容为从服务器的rsync密码，每个模块的xml文件已经写好只需要拷贝到conf文件夹即可$ cd /root/sersync &amp;&amp; mkdir bin conf etc logs$ mv sersync2 bin$ mv confxml.xml conf$ echo 'test' &gt; etc/user.pass$ chmod 600 etc/user.pass 配置文件 *.xml文件夹过滤可以设置过滤文件夹(文件)，设置了之后就不会同步该文件夹(文件)，需要注意的是在设置了过滤后启动 sersync 时 -r 参数会失效 123&lt;filter start="true"&gt; &lt;exclude expression="^upload/*"&gt;&lt;/exclude&gt;&lt;/filter&gt;s 设置监听目录和目标 ip &amp; module_name可以修改监听的本地目录及远程的 ip 和 module_name，如果需要同步到多台从服务器，配置多个 remote 即可，还支持过滤，但是在设置了过滤后启动 sersync 时 -r 参数会失效 123&lt;localpath watch="/home/work/orp/static/"&gt; &lt;remote ip="0.0.0.0" name="static"/&gt;&lt;/localpath&gt; 失败重传可以修改失败重传的时间间隔，根据实际需求修改 timeToExecute 属性 1&lt;failLog path="/tmp/rsync_fail_log.sh" timeToExecute="60"/&gt;&lt;!-- default every 60mins execute once --&gt; 运行 sersync1234# webroot模块$ /root/sersync/bin/sersync2 -r -d -o /root/sersync/conf/webroot.xml &gt; /root/sersync/logs/webroot.log 2&gt;&amp;1 &amp;# static模块$ /root/sersync/bin/sersync2 -r -d -o /root/sersync/conf/static.xml &gt; /root/sersync/logs/static.log 2&gt;&amp;1 &amp; 设置过滤需要初始化同步一次由于运行 sersync 时每个 webroot 模块都有指定 filter 过滤条件，虽然加上了 -r 参数，但是并不会进行第一次同步，所以需要我们针对每个模块手动的运行一次 sersync 命令同步一次 12# webroot模块$ root/sersync/bin/sersync2 -r -o /root/sersync/conf/webroot_full.xml cdn 回源问题问题描述因为线上有部分图片使用了百度对象存储提供的缩略服务，即在 url 后加上 @w_*，但是使用缩略服务有一个要求就是对象存储上必须有原图，当我们没有访问 cdn 没有回源的时候对象存储上是没有原图的，所以我们需要先手动的访问一次 解决方案sersync 开启 command 插件123456&lt;sersync&gt; &lt;plugin start="true" name="command"/&gt;&lt;/sersync&gt;&lt;plugin name="command"&gt; &lt;param prefix="/root/sersync/bin/curl.sh" suffix="" ignoreError="true"/&gt;&lt;!--prefix /opt/tongbu/mmm.sh suffix--&gt;&lt;/plugin&gt; curl.sh1234567891011121314151617181920#!/bin/bashIMAGE_EXTENSIONS=('gif' 'jpg' 'png' 'jpeg' 'bmp' 'ico' 'svg');sign=0;absolute_path=$1;file_src=$&#123;absolute_path#*//&#125;;extension_name=$&#123;absolute_path##*.&#125;;lowwer_extension_name=$(echo $extension_name | tr '[A-Z]' '[a-z]');for extension in $&#123;IMAGE_EXTENSIONS[*]&#125;; do if [ $extension = $lowwer_extension_name ]; then sign=1 fi;done;if [ $sign = 1 ]; then curl 'your cdn domain/upload/'$file_src &gt; /dev/null; echo 'your cdn domain/upload/'$file_src &gt;&gt; /root/sersync/logs/curl.log;fi; curl.sh 加上可执行的权限1$ chmod +x /root/sersync/bin/curl.sh 开启 command 插件监听 upload 目录配置文件 static_upload.xml123456789101112&lt;sersync&gt; &lt;localpath watch="/home/work/orp/static/upload/"&gt; &lt;/localpath&gt; &lt;plugin start="true" name="command"/&gt;&lt;/sersync&gt;&lt;plugin name="command"&gt; &lt;param prefix="/root/sersync/bin/curl.sh" suffix="" ignoreError="true"/&gt;&lt;!--prefix /opt/tongbu/mmm.sh suffix--&gt; &lt;filter start="false"&gt; &lt;include expression="(.*)\.php"/&gt; &lt;include expression="(.*)\.sh"/&gt; &lt;/filter&gt;&lt;/plugin&gt; 启动 command 插件1/root/sersync/bin/sersync2 -d -o /root/sersync/conf/static_upload.xml -m command 从服务器上传文件主服务器无法读取问题问题描述当开启负载均衡的时候，用户上传文件调用接口分发到了备用机时，文件只存在于备用机，因为不是双向同步，这时主服务器上没有该文件，所以访问该文件时负载均衡分发到主服务器会报 404，所以可以针对静态文件使用 NFS 实现网络文件系统，从而备用机访问到主服务器的今天文件 解决方案 nfsnfs 工作流程 由程序在 nfs 客户端发起存取文件的请求，客户端本地的 rpc(rpcbind)服务会通过网络向 nfs 服务端的 rpc 的 111 端口发出文件存取功能的请求 nfs 服务端的 rpc 找到对应已注册的 nfs 端口，通知客户端 rpc 服务 客户端获取正确的端口，并与 nfs daemon 联机存取数据 存取数据成功后，返回前端访问程序，完成一次存取操作 主服务器安装 nfs12345# 查看系统是否已安装nfs$ rpm -qa | grep nfs$ rpm -qa | grep rpcbind# 安装nfs$ yum install nfs-utils rpcbind -y 主服务器配置文件 /etc/exports1/home/work/orp/static/upload 172.16.0.0/16(rw,no_root_squash,sync,no_subtree_check) 重要配置文件参数说明12345678910111213141516ro：共享目录只读rw：共享目录可读可写all_squash：所有访问用户都映射为匿名用户或用户组no_all_squash（默认）：访问用户先与本机用户匹配，匹配失败后再映射为匿名用户或用户组root_squash（默认）：将来访的root用户映射为匿名用户或用户组no_root_squash：来访的root用户保持root帐号权限anonuid=&lt;UID&gt;：指定匿名访问用户的本地用户UID，默认为nfsnobody（65534）anongid=&lt;GID&gt;：指定匿名访问用户的本地用户组GID，默认为nfsnobody（65534）secure（默认）：限制客户端只能从小于1024的tcp/ip端口连接服务器insecure：允许客户端从大于1024的tcp/ip端口连接服务器sync：将数据同步写入内存缓冲区与磁盘中，效率低，但可以保证数据的一致性async：将数据先保存在内存缓冲区中，必要时才写入磁盘wdelay（默认）：检查是否有相关的写操作，如果有则将这些写操作一起执行，这样可以提高效率no_wdelay：若有写操作则立即执行，应与sync配合使用subtree_check（默认） ：若输出目录是一个子目录，则nfs服务器将检查其父目录的权限no_subtree_check ：即使输出目录是一个子目录，nfs服务器也不检查其父目录的权限，这样可以提高效率 主服务器启动 nfs，rpcbind 服务12$ service rpcbind start$ service nfs start 备用机安装 nfs12345# 查看系统是否已安装nfs$ rpm -qa | grep nfs$ rpm -qa | grep rpcbind# 安装nfs$ yum install nfs-utils rpcbind -y 备用机查看 nfs 共享目录123$ showmount -e 172.16.0.2Export list for 172.16.0.2:/home/work/orp/static/upload 172.16.0.0/16 挂载nfs1mount 172.16.0.2:/home/work/orp/static/upload /home/work/orp/static/upload 注意事项使用 docker 的情况下在挂载之后对应的 docker 容器需要重启一次，否则读取不到数据]]></content>
      <tags>
        <tag>CentOS</tag>
        <tag>rsync</tag>
        <tag>sersync</tag>
        <tag>nfs</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Shadowsocks-libev 安装笔记]]></title>
    <url>%2F2018%2F01%2F29%2Fshadowsocks-libev%2F</url>
    <content type="text"><![CDATA[安装 EPEL 源什么是企业版 Linux 附加软件包（EPEL） 企业版 Linux 附加软件包（以下简称 EPEL）是一个 Fedora 特别兴趣小组，用以创建、维护以及管理针对企业版 Linux 的一个高质量附加软件包集，面向的对象包括但不限于 红帽企业版 Linux (RHEL)、CentOS、Scientific Linux (SL)、Oracle Linux (OL) EPEL 的软件包通常不会与企业版 Linux 官方源中的软件包发生冲突，或者互相替换文件。EPEL 项目与 Fedora 基本一致，包含完整的构建系统、升级管理器、镜像管理器等等 通过 yum 命令安装 EPEL1$ yum install epel-release -y 安装依赖更新 CentOS 系统1$ yum update -y 安装 Shadowsocks-libev 依赖1$ yum install gcc gettext autoconf libtool automake make pcre-devel asciidoc xmlto c-ares-devel libev-devel libsodium-devel mbedtls-devel -y 安装并启动 Shadowsocks-libev 注：第一次安装 Shadowsocks-libev 的时候是通过 yum 源安装的，不过现在找不到 Shadowsocks-libev 的 yum 源，暂时通过 github 下载源码并启动 Shadowsocks-libev 安装 Shadowsocks-libev12345678910111213# 创建 work 用户并修改密码$ useradd work -u 1000$ echo hicoffice | passwd --stdin work$ su work$ cd /home/work# 创建 source 文件夹用于存放源码$ mkdir source &amp;&amp; cd source# 从 github 上下载源码$ wget https://github.com/shadowsocks/shadowsocks-libev/releases/download/v3.2.3/shadowsocks-libev-3.2.3.tar.gz$ cd shadowsocks-libev-3.2.3# 开始。安装$ ./configure --prefix=/home/work/orp/shadowsocks-libev$ make &amp;&amp; make install 启动 Shadowsocks-libev12# 开启 Shadowsocks-libev，更多参数通过 ss-server --help 查看$ /home/work/orp/shadowsocks-libev/bin/ss-server -s 0.0.0.0 -p 8388 -k password -m rc4-md5 &amp; 使用 Supervisor 启动 Shadowsocks-libev安装 Supervisor1$ pip install supervisor 配置 Supervisor1234$ cd /home/work/orp/shadowsocks-libev# 创建配置文件和日志存放目录$ mkdir etc logs$ vim /home/work/orp/shadowsocks-libev/etc/supervisord.conf 配置文件一览 /home/work/orp/shadowsocks-libev/etc/supervisord.conf 12345678[program:shadowsocks]command = /home/work/orp/shadowsocks-libev/bin/ss-server -s 0.0.0.0 -p 8388 -k password -m rc4-md5 &gt; /dev/null 2&gt;&amp;1 &amp;user = workautostart = trueautoresart = truestderr_logfile = /home/work/orp/shadowsocks-libev/logs/ss.stderr.logstdout_logfile = /home/work/orp/shadowsocks-libev/logs/ss.stdout.log[supervisord] 启动 Supervisor1$ cd /home/work/orp/shadowsocks-libev/etc &amp;&amp; supervisord -c /home/work/orp/shadowsocks-libev/etc/supervisord.conf]]></content>
      <tags>
        <tag>CentOS</tag>
        <tag>Shadowsocks</tag>
        <tag>Shadowsocks-libev</tag>
      </tags>
  </entry>
</search>
